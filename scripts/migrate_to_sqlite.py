#!/usr/bin/env python3
"""
–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV –≤ SQLite –±–∞–∑—É
"""

import sys
from pathlib import Path
import pandas as pd
from datetime import datetime
import sqlite3
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ core
sys.path.append(str(Path(__file__).parent.parent))

from core.database import SEODatabase

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def migrate_csv_to_sqlite():
    """–ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–æ–≤ –≤ SQLite –±–∞–∑—É"""
    
    print("üîÑ –ú–ò–ì–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• –ò–ó CSV –í SQLITE")
    print("=" * 50)
    
    # 1. –°–æ–∑–¥–∞—ë–º/–ø–æ–¥–∫–ª—é—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –±–∞–∑—É
    db_path = Path("data/seo_data.db")
    if db_path.exists():
        print(f"‚ö†Ô∏è  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {db_path}")
        print("   –•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã)")
        response = input("   [y/N]: ").strip().lower()
        if response != 'y':
            print("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return
    
    db = SEODatabase(str(db_path))
    print(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {db_path}")
    
    # 2. –ß–∏—Ç–∞–µ–º –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    import yaml
    config_path = Path("config/projects.yaml")
    
    if not config_path.exists():
        print(f"‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
        return
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    projects = config.get('projects', [])
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ –∫–æ–Ω—Ñ–∏–≥–µ: {len(projects)}")
    
    migrated_count = 0
    
    for project in projects:
        project_name = project.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')
        domain = project.get('domain', '')
        
        if not domain:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–µ–∫—Ç –±–µ–∑ –¥–æ–º–µ–Ω–∞: {project_name}")
            continue
        
        print(f"\nüìä –ü—Ä–æ–µ–∫—Ç: {project_name}")
        print(f"üåê –î–æ–º–µ–Ω: {domain}")
        
        # 3. –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–µ–∫—Ç –≤ –±–∞–∑–µ
        project_id = db.get_or_create_project(project_name, domain)
        
        # 4. –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keywords = project.get('keywords', [])
        print(f"üîë –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords)}")
        
        keyword_ids = {}
        for keyword in keywords:
            keyword_id = db.get_or_create_keyword(project_id, keyword)
            keyword_ids[keyword] = keyword_id
        
        # 5. –ú–∏–≥—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV
        csv_files = list(Path("data/history").glob(f"positions_*.csv"))
        
        for csv_file in csv_files:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∫ —ç—Ç–æ–º—É –¥–æ–º–µ–Ω—É
            file_domain = csv_file.stem.replace("positions_", "").replace("_", ".")
            
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–æ–º–µ–Ω–∞
            if domain not in file_domain and file_domain not in domain:
                continue
            
            print(f"   üìÅ –ú–∏–≥—Ä–∏—Ä—É–µ–º —Ñ–∞–π–ª: {csv_file.name}")
            
            try:
                df = pd.read_csv(csv_file)
                
                for _, row in df.iterrows():
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
                    date_str = row.get('date', '')
                    time_str = row.get('time', '')
                    
                    if not date_str or not time_str:
                        continue
                    
                    # –ù–∞—Ö–æ–¥–∏–º keyword_id
                    keyword = row.get('keyword', '')
                    if keyword not in keyword_ids:
                        # –ï—Å–ª–∏ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –Ω–µ –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        continue
                    
                    keyword_id = keyword_ids[keyword]
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏—é
                    position = row.get('position')
                    if pd.isna(position):
                        position = None
                    
                    db.save_position(
                        project_id=project_id,
                        keyword_id=keyword_id,
                        check_date=date_str,
                        check_time=time_str,
                        position=int(position) if position else None,
                        url=row.get('url', ''),
                        total_results=row.get('total_results', 100),
                        search_engine=row.get('search_engine', 'yandex')
                    )
                
                migrated_count += 1
                print(f"   ‚úÖ –§–∞–π–ª –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ {csv_file.name}: {e}")
    
    # 6. –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\n" + "=" * 50)
    print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–• –ü–û–°–õ–ï –ú–ò–ì–†–ê–¶–ò–ò:")
    
    stats = db.get_database_stats()
    print(f"   –ü—Ä–æ–µ–∫—Ç–æ–≤: {stats.get('projects_count', 0)}")
    print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {stats.get('keywords_count', 0)}")
    print(f"   –ü–æ–∑–∏—Ü–∏–π: {stats.get('positions_count', 0)}")
    print(f"   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {stats.get('competitors_count', 0)}")
    print(f"   –†–∞–∑–º–µ—Ä –±–∞–∑—ã: {stats.get('database_size_mb', 0):.2f} –ú–ë")
    
    if migrated_count > 0:
        print(f"\n‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"   –ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {migrated_count}")
        print(f"   –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: data/seo_data.db")
    else:
        print(f"\n‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print(f"   –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω–∞, –Ω–æ –ø—É—Å—Ç–∞")

if __name__ == "__main__":
    migrate_csv_to_sqlite()
